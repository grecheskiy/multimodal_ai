{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CocoCaptions\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация устройства\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Загрузка архитектуры модели\n",
    "model, processor = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Загрузка сохраненных весов\n",
    "model.load_state_dict(torch.load(\"clip.pt\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Оптимизатор и функция потерь\n",
    "tokenizer = clip.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для работы с набором данных COCO\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        super().__init__()\n",
    "        self.coco = CocoCaptions(root=root, annFile=annFile)\n",
    "        self.transform = transform  # Сохраняем transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image, captions = self.coco[idx]\n",
    "        caption = captions[0]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)  # Применяем transform\n",
    "        return image, caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка тестового набора данных\n",
    "BATCH_SIZE = 64\n",
    "val_root_dir = \"coco2017/val2017\"  # Директория с валидационными изображениями\n",
    "val_ann_file = \"coco2017/annotations/captions_val2017.json\"  # Файл аннотаций для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл аннотаций найден: coco2017/annotations/captions_val2017.json\n"
     ]
    }
   ],
   "source": [
    "# Проверка существования файла аннотаций\n",
    "if not os.path.exists(val_ann_file):\n",
    "    raise FileNotFoundError(f\"Файл аннотаций не найден: {val_ann_file}\")\n",
    "else:\n",
    "    print(f\"Файл аннотаций найден: {val_ann_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Создание DataLoader\n",
    "test_dataset = CocoDataset(\n",
    "    root=val_root_dir,\n",
    "    annFile=val_ann_file,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка соответствия изображений и подписей:\n",
      "Пример 1:\n",
      "  Подпись: A woman stands in the dining area at the table.\n",
      "  Размер изображения: torch.Size([3, 224, 224])\n",
      "--------------------------------------------------\n",
      "Пример 2:\n",
      "  Подпись: A big burly grizzly bear is show with grass in the background.\n",
      "  Размер изображения: torch.Size([3, 224, 224])\n",
      "--------------------------------------------------\n",
      "Пример 3:\n",
      "  Подпись: Bedroom scene with a bookcase, blue comforter and window.\n",
      "  Размер изображения: torch.Size([3, 224, 224])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Проверка соответствия изображений и подписей\n",
    "print(\"Проверка соответствия изображений и подписей:\")\n",
    "for i in range(3):  # Проверяем первые 3 примера\n",
    "    image, caption = test_dataset[i]\n",
    "    print(f\"Пример {i + 1}:\")\n",
    "    print(f\"  Подпись: {caption}\")\n",
    "    print(f\"  Размер изображения: {image.shape}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для вычисления метрик\n",
    "def recall_at_k(logits, targets, k=5):\n",
    "    \"\"\"\n",
    "    Вычисляет Recall@K: долю правильных предсказаний среди топ-K.\n",
    "    \"\"\"\n",
    "    _, top_k = logits.topk(k, dim=1)\n",
    "    correct = top_k.eq(targets.view(-1, 1)).sum().item()\n",
    "    return correct / len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка соответствия в батче:\n",
      "  Изображение 1: torch.Size([3, 224, 224])\n",
      "  Подпись 1: A woman stands in the dining area at the table.\n",
      "--------------------------------------------------\n",
      "  Изображение 2: torch.Size([3, 224, 224])\n",
      "  Подпись 2: A big burly grizzly bear is show with grass in the background.\n",
      "--------------------------------------------------\n",
      "  Изображение 3: torch.Size([3, 224, 224])\n",
      "  Подпись 3: Bedroom scene with a bookcase, blue comforter and window.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:01<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели CLIP\n",
    "model.eval()\n",
    "results = {\n",
    "    \"correct\": 0,  # Количество правильных предсказаний (для Recall@1)\n",
    "    \"total\": 0,    # Общее количество примеров\n",
    "    \"recall@1\": 0, # Recall@1\n",
    "    \"recall@5\": 0, # Recall@5\n",
    "    \"mrr\": 0       # Mean Reciprocal Rank\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, texts) in enumerate(tqdm(test_loader)):\n",
    "        # Проверка соответствия в батче (только для первого батча)\n",
    "        if batch_idx == 0:  # Проверяем только первый батч\n",
    "            print(\"Проверка соответствия в батче:\")\n",
    "            for i in range(min(3, len(images))):  # Проверяем первые 3 примера в батче\n",
    "                print(f\"  Изображение {i + 1}: {images[i].shape}\")\n",
    "                print(f\"  Подпись {i + 1}: {texts[i]}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "        # Перенос данных на устройство (GPU/CPU)\n",
    "        images = images.to(device)\n",
    "        texts = tokenizer(texts, truncate=True).to(device)\n",
    "        \n",
    "        # Получаем выходы модели\n",
    "        logits_per_image, logits_per_text = model(images, texts)  # Распаковываем оба выхода\n",
    "        logits = logits_per_image  # Используем logits_per_image для изображение-текст\n",
    "        \n",
    "        # Проверка формы матрицы схожести\n",
    "        assert logits.shape == (len(images), len(texts)), \\\n",
    "            f\"Ожидается форма (batch_size, batch_size), получено {logits.shape}\"\n",
    "\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        targets = torch.arange(len(images)).to(device)\n",
    "        \n",
    "        # Основные метрики\n",
    "        correct = (predictions == targets).sum().item()\n",
    "        total = images.size(0)\n",
    "        \n",
    "        # Обновление счетчиков\n",
    "        results[\"correct\"] += correct\n",
    "        results[\"total\"] += total\n",
    "        \n",
    "        # Вычисление Recall@1 и Recall@5\n",
    "        results[\"recall@1\"] += correct  # Суммируем правильные ответы\n",
    "        results[\"recall@5\"] += recall_at_k(logits, targets, k=5) * total  # Суммируем с учетом размера батча\n",
    "        \n",
    "        # Вычисление Mean Reciprocal Rank (MRR)\n",
    "        _, sorted_indices = logits.sort(descending=True)\n",
    "        for i, target in enumerate(targets):\n",
    "            rank = (sorted_indices[i] == target).nonzero().item() + 1\n",
    "            results[\"mrr\"] += 1.0 / rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет итоговых метрик\n",
    "results[\"recall@1\"] /= results[\"total\"]  # Делим на общее количество примеров\n",
    "results[\"recall@5\"] /= results[\"total\"]\n",
    "results[\"mrr\"] /= results[\"total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 86.86%\n",
      "Recall@5: 99.18%\n",
      "Mean Reciprocal Rank (MRR): 0.9236\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов\n",
    "print(f\"Recall@1: {results['recall@1'] * 100:.2f}%\")\n",
    "print(f\"Recall@5: {results['recall@5'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {results['mrr']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
